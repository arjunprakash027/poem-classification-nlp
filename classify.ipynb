{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\projects\\LARGE Projects\\poems_classification\\Poem_classification - train_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music</td>\n",
       "      <td>In the thick brushthey spend the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music</td>\n",
       "      <td>Storms are generous.                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music</td>\n",
       "      <td>—After Ana Mendieta Did you carry around the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music</td>\n",
       "      <td>for Aja Sherrard at 20The portent may itself ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Music</td>\n",
       "      <td>for Bob Marley, Bavaria, November 1980 Here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Music</td>\n",
       "      <td>For Frank X WalkerFXW: I don’t know how to sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Music</td>\n",
       "      <td>My neighbor to the left had a stroke a couple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Music</td>\n",
       "      <td>—for a sixty-seven-pound nugget of Lake Superi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Music</td>\n",
       "      <td>—Issa Rae Everybody Black is my hometown team....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Music</td>\n",
       "      <td>\"Save your hands,” my mother says, seeing me u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Genre                                               Poem\n",
       "1   Music                In the thick brushthey spend the...\n",
       "2   Music     Storms are generous.                       ...\n",
       "3   Music   —After Ana Mendieta Did you carry around the ...\n",
       "4   Music   for Aja Sherrard at 20The portent may itself ...\n",
       "5   Music   for Bob Marley, Bavaria, November 1980 Here i...\n",
       "6   Music   For Frank X WalkerFXW: I don’t know how to sw...\n",
       "7   Music   My neighbor to the left had a stroke a couple...\n",
       "8   Music  —for a sixty-seven-pound nugget of Lake Superi...\n",
       "9   Music  —Issa Rae Everybody Black is my hometown team....\n",
       "10  Music  \"Save your hands,” my mother says, seeing me u..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['Poem'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music</td>\n",
       "      <td>In the thick brushthey spend the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music</td>\n",
       "      <td>Storms are generous.                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music</td>\n",
       "      <td>—After Ana Mendieta Did you carry around the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music</td>\n",
       "      <td>for Aja Sherrard at 20The portent may itself ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Music</td>\n",
       "      <td>for Bob Marley, Bavaria, November 1980 Here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Music</td>\n",
       "      <td>For Frank X WalkerFXW: I don’t know how to sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Music</td>\n",
       "      <td>My neighbor to the left had a stroke a couple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Music</td>\n",
       "      <td>—for a sixty-seven-pound nugget of Lake Superi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Music</td>\n",
       "      <td>—Issa Rae Everybody Black is my hometown team....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Music</td>\n",
       "      <td>\"Save your hands,” my mother says, seeing me u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Genre                                               Poem\n",
       "1   Music                In the thick brushthey spend the...\n",
       "2   Music     Storms are generous.                       ...\n",
       "3   Music   —After Ana Mendieta Did you carry around the ...\n",
       "4   Music   for Aja Sherrard at 20The portent may itself ...\n",
       "5   Music   for Bob Marley, Bavaria, November 1980 Here i...\n",
       "6   Music   For Frank X WalkerFXW: I don’t know how to sw...\n",
       "7   Music   My neighbor to the left had a stroke a couple...\n",
       "8   Music  —for a sixty-seven-pound nugget of Lake Superi...\n",
       "9   Music  —Issa Rae Everybody Black is my hometown team....\n",
       "10  Music  \"Save your hands,” my mother says, seeing me u..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of feature_names: 1568\n",
      "length of x: 837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015</th>\n",
       "      <th>40</th>\n",
       "      <th>able</th>\n",
       "      <th>abyss</th>\n",
       "      <th>ache</th>\n",
       "      <th>action</th>\n",
       "      <th>added</th>\n",
       "      <th>address</th>\n",
       "      <th>admit</th>\n",
       "      <th>afraid</th>\n",
       "      <th>...</th>\n",
       "      <th>yard</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yon</th>\n",
       "      <th>yonder</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2015   40  able  abyss  ache  action  added  address  admit  afraid  ...  \\\n",
       "0     0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "1     0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "2     0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "3     0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "4     0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "..    ...  ...   ...    ...   ...     ...    ...      ...    ...     ...  ...   \n",
       "832   0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "833   0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "834   0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "835   0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "836   0.0  0.0   0.0    0.0   0.0     0.0    0.0      0.0    0.0     0.0  ...   \n",
       "\n",
       "       yard  year  years  yellow       yes  yesterday  yon    yonder  young  \\\n",
       "0    0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "1    0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "2    0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "3    0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "4    0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "..      ...   ...    ...     ...       ...        ...  ...       ...    ...   \n",
       "832  0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "833  0.2659   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "834  0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.316127    0.0   \n",
       "835  0.0000   0.0    0.0     0.0  0.210572        0.0  0.0  0.000000    0.0   \n",
       "836  0.0000   0.0    0.0     0.0  0.000000        0.0  0.0  0.000000    0.0   \n",
       "\n",
       "     youth  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "832    0.0  \n",
       "833    0.0  \n",
       "834    0.0  \n",
       "835    0.0  \n",
       "836    0.0  \n",
       "\n",
       "[837 rows x 1568 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3),max_features=10000,stop_words='english',min_df=3,max_df=0.3)\n",
    "vectorizer.fit(df['Poem'])\n",
    "\n",
    "x = vectorizer.transform(df['Poem'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"length of feature_names:\",len(feature_names))\n",
    "print(\"length of x:\",len(x.toarray()))\n",
    "\n",
    "pd.DataFrame(x.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence transformers encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)5dded/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<?, ?B/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n",
      "Downloading (…)4d81d5dded/README.md: 100%|██████████| 10.6k/10.6k [00:00<?, ?B/s]\n",
      "Downloading (…)81d5dded/config.json: 100%|██████████| 573/573 [00:00<?, ?B/s] \n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<?, ?B/s] \n",
      "Downloading (…)ded/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 26.1MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 134M/134M [00:35<00:00, 3.80MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "Downloading (…)5dded/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 754kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 352/352 [00:00<?, ?B/s] \n",
      "Downloading (…)dded/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<?, ?B/s]\n",
      "Downloading (…)4d81d5dded/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 562kB/s]\n",
      "Downloading (…)1d5dded/modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n",
      "Batches: 100%|██████████| 27/27 [00:30<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "embeddings = model.encode(df['Poem'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings))\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test SplitZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrainem,xtestem,ytrainem,ytestem = train_test_split(embeddings,df['Genre'],test_size=0.2,random_state=42)\n",
    "xtraintf,xtesttf,ytraintf,ytesttf = train_test_split(x,df['Genre'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sentence transformer model: 0.49404761904761907\n",
      "Accuracy of tfidf model: 0.4583333333333333\n",
      "classification report of sentence transformer model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Affection       0.47      0.32      0.38        22\n",
      "       Death       0.41      0.42      0.42        45\n",
      " Environment       0.63      0.69      0.65        54\n",
      "       Music       0.42      0.43      0.42        47\n",
      "\n",
      "    accuracy                           0.49       168\n",
      "   macro avg       0.48      0.46      0.47       168\n",
      "weighted avg       0.49      0.49      0.49       168\n",
      "\n",
      "classification report of tfidf model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Affection       0.35      0.27      0.31        22\n",
      "       Death       0.51      0.44      0.48        45\n",
      " Environment       0.58      0.56      0.57        54\n",
      "       Music       0.35      0.45      0.39        47\n",
      "\n",
      "    accuracy                           0.46       168\n",
      "   macro avg       0.45      0.43      0.44       168\n",
      "weighted avg       0.47      0.46      0.46       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rfem = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rftf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "\n",
    "rfem.fit(xtrainem,ytrainem)\n",
    "rftf.fit(xtraintf,ytraintf)\n",
    "\n",
    "ypredrm = rfem.predict(xtestem)\n",
    "ypredrf = rftf.predict(xtesttf)\n",
    "\n",
    "print(\"Accuracy of sentence transformer model:\",accuracy_score(ytestem,ypredrm))\n",
    "print(\"Accuracy of tfidf model:\",accuracy_score(ytesttf,ypredrf))\n",
    "\n",
    "print(\"classification report of sentence transformer model:\\n\",classification_report(ytestem,ypredrm))\n",
    "print(\"classification report of tfidf model:\\n\",classification_report(ytesttf,ypredrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
